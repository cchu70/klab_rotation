


%load_ext autoreload
%autoreload 2


from src.simple_pruning_growth_model import PruneGrowNetwork
from src.training_testing_loop import full_train, save_model_attr
from src.load_MNIST import load_MNIST
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


train_dataloader, val_dataloader, test_dataloader = load_MNIST(root='./data', subset_frac=0.1, batch_size=64)





model = PruneGrowNetwork(gamma=0.1, init_density=0.5, num_training_iter=100)

train_losses_epoch, val_losses_epoch, test_df = full_train(
    model, train_dataloader, val_dataloader, test_dataloader,
    learning_rate = 1e-2, 
    plot=False, verbose=False
)


model_pth = './data/03.grow_prune.model.state_dict.pth'
model_pth


torch.save(model.state_dict(), model_pth)


model_attr_pth = './data/03.grow_prune.model.attr.pkl'


save_model_attr(model, './data/03.grow_prune.model.attr.pkl')


import pickle

with open(model_attr_pth, 'rb') as fp:
    model_attr = pickle.load(fp)


training_losses_df = pd.DataFrame(train_losses_epoch).T
training_losses_df.columns.name = 'batch'
training_losses_df.index.name = 'epoch'

val_losses_df = pd.DataFrame(val_losses_epoch).T
val_losses_df.columns.name = 'batch'
val_losses_df.index.name = 'epoch'

stack_training_losses_df = training_losses_df.stack().reset_index().rename(columns={0: 'loss'})
stack_training_losses_df.index = stack_training_losses_df['epoch'].astype(str) + '-' + stack_training_losses_df['batch'].astype(str)
stack_training_losses_df.index.name = 'index'
stack_val_losses_df = val_losses_df.stack().reset_index().rename(columns={0: 'loss'})
stack_val_losses_df.index = stack_val_losses_df['epoch'].astype(str) + '-' + stack_val_losses_df['batch'].astype(str)
stack_val_losses_df.index.name = 'index'


training_losses_fn = './data/03.training_losses.tsv'
val_losses_fn = './data/03.val_losses.tsv'

training_losses_df.to_csv(training_losses_fn, sep='\t')
val_losses_df.to_csv(val_losses_fn, sep='\t')





fig, axes = plt.subplots(3, 1, figsize=(10, 5), sharex=True, height_ratios=[1, 5, 5])
axes[0].imshow(np.array(model_attr['grow_prune_history']).reshape(1, -1), cmap='gray')
axes[0].set_yticks([])
axes[0].set_ylabel("Grow/prune", rotation=0, ha='right')

axes[1].plot(np.array(model_attr['synapse_count_history']) / model.total_size, c='k') 
axes[1].set_ylabel("Total model size")

sns.scatterplot(test_df.reset_index(), x='epoch', y='test_err', ax=axes[2], c='k', s=5) 
axes[2].set_ylim(0, 1.0)
plt.tight_layout()
plt.show()


fig, ax = plt.subplots(figsize=(10, 5))
sns.scatterplot(stack_training_losses_df.reset_index(), x='index', y='loss', label='Training loss', alpha=0.5, c='gray', s=0.5)
sns.lineplot(stack_val_losses_df.reset_index(), x='index', y='loss',  label='Validation loss', c='red')
plt.xticks([])
plt.xlabel('Training and validation epoch/batch')
plt.show()








new_model = PruneGrowNetwork(gamma=0.1, init_density=0.5, num_training_iter=50)

new_train_losses_epoch, new_val_losses_epoch, new_test_df = full_train(
    new_model, train_dataloader, val_dataloader, test_dataloader,
    learning_rate = 1e-2, 
    plot=True, verbose=False
)



