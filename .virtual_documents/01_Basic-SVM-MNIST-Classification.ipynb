


import numpy as np
import pandas as pd
import os
import tqdm





from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import validation_curve, KFold, cross_val_score, GridSearchCV
import matplotlib.pyplot as plt
import seaborn as sns


from torch.utils.data import Dataset
from torchvision import datasets # get Fashion-MNIST
from torchvision.transforms import ToTensor


training_data = datasets.MNIST(
    root="data",
    train=True,
    download=False,
    # transform=ToTensor(),
)

test_data = datasets.MNIST(
    root="data",
    train=False, # get testing data
    download=False,
    # transform=ToTensor()
)





def dataset_to_df(dataset):
    labels = []
    pixels = []
    for pix, label in tqdm.tqdm(dataset):
        labels.append(label)
        pixels.append(np.array(pix).flatten())
    df = pd.DataFrame(np.array(pixels), index=labels)
    df.index.name = 'label'
    pixel_cols = df.columns.tolist()
    df = df.reset_index()
    return df, pixel_cols


train_df, pixel_cols = dataset_to_df(training_data)
test_df, pixel_cols = dataset_to_df(test_data)


display(train_df.head())
display(test_df.head())


print(train_df.isna().any().any())
print(test_df.isna().any().any())


display(train_df.describe())
display(test_df.describe())


print(train_df.info())
print(test_df.info())


print(train_df.columns)
print(test_df.columns)


sns.barplot(train_df["label"].value_counts())
plt.title("Training Data Label Counts")
plt.show()


# Plot a number
for num in [4, 7]:
    plt.imshow(train_df.query(f"label == {num}").iloc[0][pixel_cols].values.reshape(28, 28), cmap='gray')
    plt.show()





train_df[pixel_cols].mean().hist()
plt.xlabel('Mean pixel value')
plt.ylabel('Number of pixels')
plt.show()


# separate labels
train_y = train_df['label'].copy()
train_X = train_df[pixel_cols].copy()

# Normalize
train_X /= 255.0 # max pixel value

norm_test_df = test_df[pixel_cols].copy()
norm_test_df /= 255.0

print(train_X.shape)
print(norm_test_df.shape)


# Scale features
from sklearn.preprocessing import scale
# Standardize dataset along an axis. Center to the mean and component wise scale to unit variance
train_X_scaled = scale(train_X)


train_X_scaled


# train test split
split_X_train, split_X_test, split_y_train, split_y_test = train_test_split(
    train_X_scaled,
    train_y,
    test_size=0.3,
    train_size=0.2,
    random_state=10
)








model_linear = SVC(kernel='linear')
model_linear.fit(split_X_train, split_y_train)

y_pred = model_linear.predict(split_X_test)


from sklearn import metrics


print(f"Accuracy: {metrics.accuracy_score(y_true=split_y_test, y_pred= y_pred)}")
print(metrics.confusion_matrix(y_true=split_y_test, y_pred= y_pred))








non_linear_model = SVC(kernel='rbf')
non_linear_model.fit(split_X_train, split_y_train)
non_lin_y_pred = non_linear_model.predict(split_X_test)


print(f"Accuracy: {metrics.accuracy_score(y_true=split_y_test, y_pred= non_lin_y_pred)}")
print(metrics.confusion_matrix(y_true=split_y_test, y_pred= non_lin_y_pred))





# Kfold provides train/test indices to split data in train/test sets. 
# Each fold is used once a validation, while the k-1 remaining folds are the training set
folds = KFold(n_splits=5, shuffle=True, random_state=10)
folds


# To test
hyper_params = [{
    'gamma': [1e-2, 1e-3, 1e-4],
    'C': [5, 10]
}]


rbf_model = SVC(kernel='rbf')


rbf_model_cv = GridSearchCV(
    estimator=rbf_model,
    param_grid=hyper_params,
    scoring='accuracy',
    cv=folds,
    verbose=1,
    return_train_score=True,
    # n_jobs=4,
)


split_X_train.shape



rbf_model_cv.fit(split_X_train[:1000, :], split_y_train[:1000]) # taking too long to run


cv_results_df = pd.DataFrame(rbf_model_cv.cv_results_)
cv_results_df['param_C'] = cv_results_df['param_C'].astype(str)
cv_results_df


accuracy_scores_df = cv_results_df.set_index(['param_gamma', 'param_C'])[
['mean_test_score', 'mean_train_score']
].stack().reset_index().rename(columns={'level_2': 'mean_score_source', 0: 'accuracy_score'})
accuracy_scores_df


sns.lineplot(
    accuracy_scores_df,
    x='param_gamma',
    y='accuracy_score',
    hue='param_C',
    style='mean_score_source'
)
plt.xscale('log')
plt.show()


best_score = rbf_model_cv.best_score_
best_hyperparams = rbf_model_cv.best_params_
print(best_score, best_hyperparams)





opt_model = SVC(kernel="rbf", **best_hyperparams)
opt_model.fit(split_X_train, split_y_train)
opt_y_pred = opt_model.predict(split_X_test)


print(f"Accuracy: {metrics.accuracy_score(y_true=split_y_test, y_pred= opt_y_pred)}")
print(metrics.confusion_matrix(y_true=split_y_test, y_pred= opt_y_pred))



